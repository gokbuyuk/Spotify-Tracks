---
title: "Spotify tracks popularity prediction"
author: "Adnan Cihan Cakar, Gokcen Buyukbas"
date: "5/5/2021"
output: slidy_presentation
---

```{r setup, include=FALSE, message=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=TRUE, autodep=TRUE, cache.comments=FALSE,
               message=FALSE, warning=FALSE)

rm(list=ls())
set.seed(1)
```


```{r, message=FALSE, echo=FALSE, warning=FALSE}
library(dplyr)
library(mgcv)
library(ResourceSelection)
library(mgcv)
library(alr4)
library(tidyverse)
library(pscl)
library(randomForest)
library(reshape2)
library(lme4)
library(ROCR)
library(pbkrtest)
library(RLRsim)
library(kableExtra)
library(magick)
library(htmlTable)

#setwd("C:/Users/aciha/Google Drive/curwordir/S632/final project")
#setwd("C:/Users/aciha/Google Drive/curwordir/S632/final project")
data = read.csv("./Spotify-Tracks/spotify/data.csv")
album_artist_data = read.csv("./Spotify-Tracks/spotify/data_with_album_and_artist.csv")
data = distinct(data)
album_artist_data = distinct(album_artist_data)
tracks = merge(album_artist_data, data, by = "id")
tracks = subset(tracks, select=-c(id,artists,name,explicit))

getSeason <- function(date) {
   WS <- as.Date("2012-12-15", format = "%Y-%m-%d") # Winter Solstice
   SE <- as.Date("2012-3-15",  format = "%Y-%m-%d") # Spring Equinox
   SS <- as.Date("2012-6-15",  format = "%Y-%m-%d") # Summer Solstice
   FE <- as.Date("2012-9-15",  format = "%Y-%m-%d") # Fall Equinox

   # Convert dates from any year to 2012 dates
   d <- as.Date(strftime(date, format="2012-%m-%d"))

   ifelse (d >= WS | d < SE, "Winter",
     ifelse (d >= SE & d < SS, "Spring",
       ifelse (d >= SS & d < FE, "Summer", "Fall")))
}

tracks$release_date = as.Date(tracks$release_date)
tracks$season = apply(as.data.frame(tracks$release_date), 1, getSeason)
tracks = subset(tracks, select=-c(release_date))

tracks$season = as.factor(tracks$season)
tracks$key = as.factor(tracks$key)
tracks$album_type = as.factor(tracks$album_type)
tracks$mode = as.factor(tracks$mode)
tracks$duration_ms = tracks$duration_ms/1000

tracks$binaryPop = ifelse(tracks$popularity<50,0,1)
tracks$intPop = round(tracks$popularity, 0)
tracks$ratePop = tracks$popularity/100
tracks = na.omit(tracks)

numData = subset(tracks, select=-c(album, artist, album_type, season, key, mode))
tracks20 = tracks[tracks$year==2020,]
tracks20 = subset(tracks20, select=-c(year))
```

# **Reasearch Questions:** 
* 1. What song features play a significant role in a song's popularity?
* 2. Do the features affecting the popularity of tracks change in years?

# **Data**
* We mainly used a Kaggle data (https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks) for this project. This data consists of 174389 songs with 19 features described below. 

### **Primary:**
* id (Id of track generated by Spotify)

### **Numerical variables:**
<div class="col2">
* acousticness (Ranges from 0 to 1)
* danceability (Ranges from 0 to 1)
* energy (Ranges from 0 to 1)
* duration_ms (Integer typically ranging from 200k to 300k)
* instrumentalness (Ranges from 0 to 1)
* valence (Ranges from 0 to 1)
* popularity (Ranges from 0 to 100)
* tempo (Float typically ranging from 50 to 150)
* liveness (Ranges from 0 to 1)
* loudness (Float typically ranging from -60 to 0)
* speechiness (Ranges from 0 to 1)
* year (Ranges from 1921 to 2020)
</div>

### **Categorical variables:**
* mode (0 = Minor, 1 = Major)
* explicit (0 = No explicit content, 1 = Explicit content)
* key (All keys on octave encoded as values ranging from 0 to 11, starting on C as 0, C# as 1 and so onâ€¦)
* artists (List of artists mentioned)
* release_date (Date of release mostly in yyyy-mm-dd format, however precision of date may vary)
* name (Name of the song)

# **Data processing:**
- We added three variables.
We obtained  *album type* and *album* using Python Spotify API for each track. 
We created a new categorical variable, *season*, based on the release date.

- We then removed some variables such as id, and name of the tracks, and  converted the categorical variables to factor. Lastly, we added different interpretations of popularity variable, such as a binary response, binaryPop (0 if popularity$<50$, and 1 otherwise).

# **Research Question 1: Significance of Features**
For the first research question we focused on data from 2020.

**Strategy:** We used the model selection techniques for the binary popularity response with variables acousticness, danceability, energy, duration, instrumentalness, valence, tempo, liveness, loudness, speechiness, season, mode, key, and album type. The analysis gave us the following model:

```{r}
lm1 = glm(formula = binaryPop ~ season + album_type + duration_ms + loudness + liveness + instrumentalness + key + valence + mode + danceability, family = binomial, data = tracks20)
summary(lm1)
```

# **Research Question 1: Logistic Regression Diagnostics**
Then we tested the goodness of fit for this model.

```{r}
grouped_tracks20 = mutate(tracks20, residuals=residuals(lm1), eta=predict(lm1)) %>%
  group_by(ntile(eta, 100)) %>%
  summarise(residuals=mean(residuals), eta=mean(eta))

par(mfrow=c(1,2))
plot(residuals ~ eta, grouped_tracks20, xlab=expression(eta))
qqnorm(grouped_tracks20$residuals)

print(paste("P-value =", hoslem.test(predict(lm1), tracks20$binaryPop,100)$p.value))
```

# **Binomial Regression**
Since logistic regression didn't provide a good model, we tried to fit a binomial regression model with the integer valued popularity as response.

```{r}
lm2 = glm(formula = cbind(intPop, 100 - intPop) ~ album_type + instrumentalness + 
    danceability + season + duration_ms + valence + loudness + 
    energy + key + liveness + acousticness + mode + tempo + speechiness, 
    family = binomial, data = tracks20)
summary(lm2)
```

# **Binomial Regression Diagnostics**
Then we tested the goodness of fit for this model.
```{r}
print(paste("P-value =", 1-pchisq(sum(residuals(lm2,type="pearson")^2), lm2$df.residual)))
par(mfrow=c(1,2))
plot(predict(lm2),residuals(lm2,type="pearson"), xlab="Linear Predictor", ylab="Pearson Residuals")
qqnorm(residuals(lm2,type="pearson"))
```

# **Resulting Model**
Neither logistic regression and binomial regression providing a good model, we tried other techniques, such as Poisson regression, beta regression, and transformations. Ultimately, the best model we obtained was 

```{r}
lm3 = glm(binaryPop ~I(valence^0.5)+album_type+log(duration_ms)+key+log(liveness)+season+mode+loudness+instrumentalness, family = binomial, tracks20)
summary(lm3)
```

# **Random Effects**

Next we analyzed the significance of artist, and album using a mixed linear model. We started with the fixed effects from our previous analysis and added album, artist, and album type as nested random effects. Then we applied the model selection techniques for fixed models and then random model. As the resulting model we obtained

```{r}
rem = lmer(popularity ~ 1+I(valence^0.5)+album_type+season+instrumentalness+(1|artist)+(1|artist:album), tracks20)
summary(rem)
```

# **Random Forest**

The model based approach was not successful to provide a good enough model to talk about the significance of features. So we tried an algorithmic approach. We used both classification and regression with  corresponding responses.

First, we determined the best number of variables to use at each node and maximum number of end nodes for trees. For this;

* We divided the data into training and test sets,
* For classification trees, we measured the accuracy, sensitivity, specificity, and F1 score on the test set.
* For regression trees, we measured the accuracy on test set using Mean Squared Error.

The best number of variables to use at each node is 6 and random forest best performance when there is no limit of maximum number of end nodes for trees.


# **Random Forest**

```{r, include=F, echo=F}
performance = function(preds, y){
   n = length(y)
   tp = sum(preds==1 & y==1)
   tn = n - sum(preds==1 | y==1)
   fp = sum(preds==1 & y==0)
   fn = sum(preds==0 & y==1)
   acc = (tp+tn)/(tp+tn+fp+fn)
   sens = tn/(tn+fn)
   spec = tp/(tp+fp)
   recall = tp/(tp+fn)
   f1 = 2*recall*spec/(recall+spec)
   
   return(c("Accuracy"=acc,"Sensitivity"= sens,"Specificity"=spec, "F1" = f1))
}
```
```{r}
tracks20$binaryPop = factor(tracks20$binaryPop)
train = sample(1:nrow(tracks20), nrow(tracks20)/5)
tracks20.train = tracks20[train,]
tracks20.test = tracks20[-train,]

forest = randomForest(binaryPop~.-popularity-ratePop-intPop-album-artist, tracks20, importance = TRUE, mtry = 6)
varImpPlot(forest)
```

The two most important features are *album type* and *instrumentalness*. 

# **Random Forest vs. Random Guess**
```{r}
set.seed(666)
randomGuesses = sample(c(0,1), size = length(tracks20.test$binaryPop), replace = TRUE, prob = c(0.5,0.5))
RandomGuess = performance(randomGuesses,tracks20.test$binaryPop)

forest20 = randomForest(binaryPop~.-popularity-ratePop-intPop-album-artist, tracks20.train, importance = TRUE)
RandomForest = performance(preds = predict(forest20, newdata = tracks20.test, type = "Class"),y = tracks20.test$binaryPop)

kbl(round(rbind(RandomGuess, RandomForest),2))%>%
  kable_material(c("striped", "hover"))
```

# **Random Forest (Year by Year)**
Next, we used the data from each year between 2010 and 2021 to trained a random forest algorithm for each year to investigates if the significance of features of the songs change over time. 

We observed that even though the topmost important features have alternated with each other, there was not a drastic change in the list of five most important features over the years. 

```{r}
set.seed(666)
importanceFrame = data.frame(row.names = row.names(importance(forest)))
for (i in 2010:2021){
   yearly_tracks = tracks[tracks$year==i,]
   forest = randomForest(popularity~.-binaryPop-ratePop-intPop-album-artist-year, yearly_tracks, mtry = 6)
   importanceData = importance(forest)
   colnames(importanceData) = i
   importanceFrame = cbind(importanceFrame, importanceData)
}
```

```{r}
yearNames = colnames(importanceFrame)
importanceFrame$Features = row.names(importanceFrame)
newFrame = pivot_longer(importanceFrame,all_of(yearNames),names_to= "Year", values_to = "Importance")
newFrame$Year = as.numeric(newFrame$Year)
```

```{r}
ggplot(newFrame, aes(x = Year, y = Importance, color = Features))+geom_line()+ scale_x_continuous(breaks = seq(2010, 2021, by = 2))
```

# **Conclusion**:
1.	The song features *album type*,  *instrumentalness* were were the most important features to predict popularity; followed by *dancebility*, *duration* and *liveness*. 
2.	*Instrumentalness* and *album type* remained the two most important features even though their order alternated over the years. The list of top five most important features has not changed much. 

# **References**
[1] https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks
[2] Extending the Linear Model with R, Julian Faraway, Second edition, Boca Raton : CRC Press, Taylor & Francis Group, [2016] and Â©2016
[3] https://developer.spotify.com/documentation/web-api

# **Thank you**
